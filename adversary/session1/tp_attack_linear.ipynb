{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Robust methods for Machine Learning\n",
    "\n",
    "## Let's start simple: attack a linear model\n",
    "\n",
    "#### Tutorial #1 (Anne Gagneux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to attack a linear model for binary classification.\n",
    "We focus on MNIST dataset where we only keep the $3$ and $7$ digits.\n",
    "In our setting, $\\mathbf X_{\\text{train}}$ is the training dataset of images ($7$ and $3$) and $y_{\\text{train}}$ are the matching ground-truth labels.\n",
    "\n",
    "Our linear model builds a decision function based on a hyperplane:\n",
    "$$ y_{\\text{pred}} = \\text{sign} (w^T x + b) $$\n",
    "\n",
    "The algorithm, i.e. Logistic regression, learns $w$ and $b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST\n",
    "mnist_train = datasets.MNIST(\"./data\", train=True, download=True)\n",
    "mnist_test = datasets.MNIST(\"./data\", train=False, download=True)\n",
    "\n",
    "# Only keep 3 and 7\n",
    "train_idx = (mnist_train.targets == 3) + (mnist_train.targets == 7)\n",
    "\n",
    "mnist_train.data = mnist_train.data[train_idx]\n",
    "mnist_train.targets = mnist_train.targets[train_idx]\n",
    "\n",
    "test_idx = (mnist_test.targets == 3) + (mnist_test.targets == 7)\n",
    "mnist_test.data = mnist_test.data[test_idx]\n",
    "mnist_test.targets = mnist_test.targets[test_idx]\n",
    "\n",
    "X_train, y_train = mnist_train.data.numpy(), mnist_train.targets.numpy()\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "\n",
    "# scale the data to ease optimization\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test, y_test = mnist_test.data.numpy(), mnist_test.targets.numpy()\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train logistic regression\n",
    "logreg = LogisticRegression(solver='lbfgs', max_iter=2000)\n",
    "logreg.fit(X_train, y_train)\n",
    "print('accuracy on test set = {}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = X_test[0]\n",
    "# Pick a point in the dataset\n",
    "\n",
    "\n",
    "def show(x, classifier, ax=None):\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(1, 1)\n",
    "    ax.set_title('Prediction: %s \\n Confidence: %d %%' %\n",
    "              (classifier.predict([x])[0],\n",
    "               100 * classifier.predict_proba([x]).max()),\n",
    "              fontsize=14)\n",
    "    xx = scaler.inverse_transform([x]).reshape((28, 28))\n",
    "    ax.imshow(xx, cmap=plt.cm.gray_r, vmin=0, vmax=255)\n",
    "    ax.axis('off')\n",
    "\n",
    "\n",
    "show(x1, logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Projection](decision-boundary.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we denote $x_1$ our image. \n",
    "The shorter distance to a point at the frontier is the orthogonal projection on the hyperplane $w^T x + b = 0$.\n",
    "\n",
    "<span style=\"color:orange\">**Write the projection operator onto the hyperplane**</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = logreg.coef_[0]\n",
    "b = logreg.intercept_\n",
    "\n",
    "x_L2 = ... # TO COMPLETE: project x onto the  decision frontier w @ x + b = 0\n",
    "x_L2 = x1 - ( b + w @ x1) / np.linalg.norm(w) ** 2 * w # TO COMPLETE: project x onto the decision frontier w @ x + b = 0\n",
    "\n",
    "# print(w @ x_L2 + b)  # should be 0\n",
    "show(x_L2, logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to force prediction of $x_1$ to be a $3$ ? \n",
    "\n",
    "<span style=\"color:orange\">**Write an explicit formula forcing $x_1$ to be misclassified as a 3**</span>\n",
    "\n",
    "\n",
    "![Projection](decision-boundary-2.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x3 = ... # TO COMPLETE\n",
    "show(x3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to now, we have minimized the $\\ell_2$ distance.\n",
    "Indeed, the orthogonal projection writes as:\n",
    "$$\\min_x \\Vert x-x_1 \\Vert_2 \\text{ subject to } w^Tx+ b = 0$$\n",
    "\n",
    "What if we want to minimize the maximum variation of each pixel ? \n",
    "$\\rightarrow$ We use the $\\ell_\\infty$ distance.\n",
    "\n",
    "Our new minimization problem is:\n",
    "$$\\min_x \\Vert x-x_1 \\Vert_\\infty \\text{ subject to } w^Tx+ b = 0$$\n",
    "\n",
    "<span style=\"color:orange\">**Solve the $\\ell_\\infty$ optimization problem**</span>\n",
    "\n",
    "*Recall (Holder's Inequality)*\n",
    "$$|x^T y| \\leq \\Vert x \\Vert_1 \\Vert y \\Vert_\\infty$$\n",
    "\n",
    "![Projection infty](decision-boundary-infty.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_Linfty = x1 - (b + w @ x1) / np.sum(np.abs(w)) * np.sign(w)\n",
    "show(x_Linfty, logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus**: solve the <span style=\"color:orange\">**Solve the $\\ell_1$ optimization problem**</span>\n",
    "\n",
    "You can still use Holder's inequality, but permuting $x$ and $y$ this time.\n",
    "$$|x^T y| \\leq \\Vert y \\Vert_1 \\Vert x \\Vert_\\infty$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perturb_L1 = np.zeros_like(w)\n",
    "idx = np.argmax(np.abs(w))\n",
    "perturb_L1[idx] = np.sign(w[idx])\n",
    "x_L1 = x1 - (b + w @ x1) / np.max(np.abs(w)) * perturb_L1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the original digit together with the 3 attacks ($\\ell_2, \\ell_\\infty, \\ell_1$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 4, constrained_layout=True, figsize=(10, 20))\n",
    "for x, ax in zip([x1, x_L1, x_L2, x_Linfty], axes):\n",
    "    show(x, logreg, ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualize the adversarial perturbations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(10, 9), constrained_layout=True)\n",
    "\n",
    "for x_adv, ax in zip([x_Linfty, x_L2, x_L1], axes):\n",
    "    im = ax.imshow((x1 - x_adv).reshape(28, 28), cmap=plt.cm.gray_r,)\n",
    "    fig.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n",
    "\n",
    "for ax in axes:\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

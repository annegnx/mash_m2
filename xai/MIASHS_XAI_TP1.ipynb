{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCfkubpfRjHO"
      },
      "source": [
        "# XAI - TP1: Interpreting Model Predictions using SHAP\n",
        "### Anne Gagneux\n",
        "\n",
        "\n",
        "**Topic**: SHAP stands for SHapley Additive exPlanations. The goal of SHAP is to assign to each feature an importance value for a particular prediction. SHAP views the explanation of a model's predictions as a model itself. The underlying idea is that for a simple model, the model is interpretable by nature. For instance, with a linear model, the larger the coefficient for one feature is, the more important this feature is to the prediction.\n",
        "\n",
        "So to understant a complex mode, the idea is to use as an explanation a simpler model that gives the same predictions as the complex one.\n",
        "\n",
        "**Method**\n",
        "Let $f$ be the original prediction model to be explained and $g$ the explanation model.\n",
        "\n",
        "$$g(z) = \\phi_0 + \\sum_{i=1}^M \\phi_i z_i$$\n",
        "Where $z \\in \\{0,1\\}^M$ is a binary variable and $M$ is the number of input features.\n",
        "\n",
        "**Shapley values**  Let's say we want to compute the importance of a feature $i$. We consider all feature subsets $S \\subset F$ (where $F$ is the set of all features). Two models are trained: one with that feature present $f_{S\\cup \\{i\\}}$ and a model $f_S$ without the feature. Then, the predictions of the two models are compared:\n",
        "$$ f_{S\\cup \\{i\\}}(x_{S\\cup \\{i\\}}) - f_{S}(x_{S}) $$\n",
        "\n",
        "Shapley values are then computed by averaging for all possible subsets not containing the studied feature $i$:\n",
        "$$\\phi_i = \\sum_{S \\subset F ∖ \\{i\\}} \\frac{|S|!(|F|-|S|-1)!}{|F|!} \\left( f_{S\\cup \\{i\\}}(x_{S\\cup \\{i\\}}) - f_{S}(x_{S}) \\right)$$\n",
        "\n",
        "Here, our binary variable for $z$ in $g(z)$ is computed as $x = h_x(z)$ where we set to $0$ the coefficients that are not included in the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jibtlZrxYw8g"
      },
      "source": [
        "### In practice:\n",
        "\n",
        "All possible coalitions (sets) of feature values have to be evaluated with and without the $i$-th feature to calculate the exact Shapley value: it quickly becomes untracktable. To avoid this problem, we can approximate Shapley values doing Monte Carlo:\n",
        "\n",
        "$$\\hat \\phi_i = \\frac{1}{N} \\sum_{i=1}^N \\left(f(x_{+j}^m) - f(x^m_{-j}) \\right)$$\n",
        "\n",
        "  where $x_{+j}^m$ has a random number of feature values replaced by random data, except for the feature $i$ and  $x^m_{-j}$ is equal to $x_{+j}^m$ except for the $i$-th component which is also random.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUVMx2q_Z9Le"
      },
      "source": [
        "## First studycase: the Adult Census Income dataset\n",
        "\n",
        "Predict whether income exceeds $50K/yr based on census data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AgBBxRegYwWx"
      },
      "outputs": [],
      "source": [
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ppq9yLu7RZ3n",
        "outputId": "a0f43e58-8792-46f9-8843-b65800f6d3ac"
      },
      "outputs": [],
      "source": [
        "#Run if shap not installed\n",
        "! pip install shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQjS41_gakZP"
      },
      "outputs": [],
      "source": [
        "import shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDmyOMdUa4vx"
      },
      "outputs": [],
      "source": [
        "from sklearn import model_selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJEC-OpKalxA"
      },
      "outputs": [],
      "source": [
        "# a classic housing price dataset\n",
        "X, y = shap.datasets.adult(n_points=2000)\n",
        "X_display, y_display = shap.datasets.adult(n_points=2000, display=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzhuLPKBaylY"
      },
      "outputs": [],
      "source": [
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(X,\n",
        "                                                                    y,\n",
        "                                                                    test_size=0.1,\n",
        "                                                                    random_state=80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uz8ZTcH7r0jD"
      },
      "source": [
        "First, let's inspect the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykdBzQENbFsB",
        "outputId": "06dead0a-2102-41db-cba5-36901297e68d"
      },
      "outputs": [],
      "source": [
        "X_display.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "VcQUpRv6sj9L",
        "outputId": "b72e9f38-37e0-420e-a7f4-d86b5632ab15"
      },
      "outputs": [],
      "source": [
        "X_display.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lgrfLGEabeC"
      },
      "source": [
        "### Let's start simple: logistic regression\n",
        "\n",
        "\n",
        "$$p_{\\mathbf{\\theta}}(y=1|\\mathbf{x}) = \\frac{1}{1+\\exp(-\\mathbf{\\theta^\\top x})}$$\n",
        "\n",
        "$$p_{\\mathbf{\\theta}}(y=0|\\mathbf{x}) = \\frac{\\exp(-\\mathbf{\\theta^\\top x})}{1+\\exp(-\\mathbf{\\theta^\\top x})}$$\n",
        "\n",
        "To compute the optimal parameters $\\mathbf{\\theta^*}$ of our model, we minimize the negative log likelihood.\n",
        "\n",
        "$$\\mathbf{\\theta^*} = {\\arg \\min}_{\\mathbf{\\theta}} J(\\mathbf{\\theta})$$\n",
        "\n",
        "with the loss $ J(\\mathbf{\\theta}) $ defined as follows:\n",
        "\n",
        "\\begin{align} J(\\mathbf{\\theta}) & = - \\log \\prod_{i=1}^N p_{\\mathbf{\\theta}}(y^{i}|\\mathbf{x}^{i}) \\\\ &= - \\sum_{i=1}^N y^{i} \\log p_{\\mathbf{\\theta}}(y=1|\\mathbf{x^i}) + (1-y^i) \\log p_{\\mathbf{\\theta}}(y=0|\\mathbf{x^i})\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "TndHRjg9ay7M",
        "outputId": "b346cdb3-d657-4423-a899-7c279d77bae0"
      },
      "outputs": [],
      "source": [
        "# a simple linear model\n",
        "model = sklearn.linear_model.LogisticRegression()\n",
        "model.fit(x_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDG7RO1ybJBr"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(x_test)  # make the prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKWiRZ0PbOIm",
        "outputId": "47aab555-11e1-4bdd-e368-a42322429902"
      },
      "outputs": [],
      "source": [
        "((y_pred == y_test)).mean()  # compute the accuracy of our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zzBGwsuIcqZ-"
      },
      "outputs": [],
      "source": [
        "def model_adult_proba(x):\n",
        "    return model.predict_proba(x)[:, 1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHsE2vHdbQyY",
        "outputId": "f2fc17da-f35f-4988-c03d-4a3840b5f63b"
      },
      "outputs": [],
      "source": [
        "print(\"Model coefficients:\\n\")\n",
        "for i in range(X.shape[1]):\n",
        "    print(X.columns[i], \"=\", model.coef_[0, i].round(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_nKht8FeHod"
      },
      "source": [
        "**Remark**: Because the values of the features are not normalized, the coefficients themselves don't tell much. A change of $1$ for the number of hours per week does not have the same meaning as a change of $1$ in the marital status."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "qeptFN0Yedal",
        "outputId": "173113c3-ee48-41ca-c038-2904f7f81c3c"
      },
      "outputs": [],
      "source": [
        "shap.partial_dependence_plot(\n",
        "    \"Capital Gain\",\n",
        "    model_adult_proba,\n",
        "    X,\n",
        "    ice=False,\n",
        "    model_expected_value=True,\n",
        "    feature_expected_value=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gzqCSGbztapk"
      },
      "outputs": [],
      "source": [
        "def model_adult_log_odds(x):\n",
        "    p = model.predict_log_proba(x)\n",
        "    return p[:, 1] - p[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        },
        "id": "VoIgTYgqtePt",
        "outputId": "58925956-b233-4f5f-ce1d-f0c3d748fced"
      },
      "outputs": [],
      "source": [
        "shap.partial_dependence_plot(\n",
        "    \"Capital Gain\",\n",
        "    model_adult_log_odds,\n",
        "    X,\n",
        "    ice=False,\n",
        "    model_expected_value=True,\n",
        "    feature_expected_value=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ntyN1GxTuAll"
      },
      "source": [
        "**QUESTION**: For the partial dependence plot, what difference do you observe using log-odds instead of probabilities in the model's outputs ? How do you explain it ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jeWDinUxDYb"
      },
      "source": [
        "### Now, we train a XGBoost Classifier which is a much more complex model, difficult to interpret."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTINO3zyxips",
        "outputId": "be3bc879-2a8f-4f1a-f131-b6bca5f311dc"
      },
      "outputs": [],
      "source": [
        "import xgboost\n",
        "# train XGBoost model\n",
        "X, y = shap.datasets.adult()\n",
        "params_xgb = {\n",
        "    \"n_estimators\": 200,\n",
        "    \"max_depth\": 8,\n",
        "    \"learning_rate\": 0.05,\n",
        "}\n",
        "X_display, y_display = shap.datasets.adult(display=True)\n",
        "model = xgboost.XGBClassifier().fit(X, y)\n",
        "# compute SHAP values\n",
        "explainer = shap.TreeExplainer(model, X,  model_output=\"raw\")\n",
        "shap_values = explainer(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhuoDk9bxpWg"
      },
      "source": [
        "#### Local interpretability: How to explain a single prediction ?\n",
        "\n",
        "The output of the model is equal to $\\log \\left(\\frac{p ( y=1 | \\mathbf{x})}{1-p(y = 1|\\mathbf{x})} \\right)$, i.e.:\n",
        "\n",
        "\\begin{align}\n",
        "\\log \\left(\\frac{p ( y=1 | \\mathbf{x})}{1-p(y = 1|\\mathbf{x})} \\right) & > 0\\\\\n",
        "\\iff \\frac{p ( y=1 | \\mathbf{x})}{1-p(y = 1|\\mathbf{x})} & > 1 \\\\\n",
        "\\iff p ( y=1 | \\mathbf{x}) > 1-p(y = 1|\\mathbf{x}) & = p(y = 0|\\mathbf{x})\n",
        "\\end{align}\n",
        "\n",
        "So, positive values of the output mean that the probability that the person has an income greater than 50k dollars / a year is larger than $0.5$.\n",
        "\n",
        "**Tools**:\n",
        "- *Force plot*: on a force plot, we observe how each feature increases the probability of having an income greater than $50k/yr (in red) or decreases it (in blue).\n",
        "\n",
        "- *Waterfall plot*: The bottom of a waterfall plot starts as the expected value of the model output, and then each row shows how the positive (red) or negative (blue) contribution of each feature moves the value from the expected model output over the background dataset to the model output for this prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpbMNKWkyYK1"
      },
      "outputs": [],
      "source": [
        "# choose an individual (a sample)\n",
        "sample_index = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "lymvakYiydBr",
        "outputId": "4afc0cfe-71b6-431f-93a0-78847ded8864"
      },
      "outputs": [],
      "source": [
        "shap.force_plot(explainer.expected_value,\n",
        "                shap_values.values[sample_index, :], X_display.iloc[sample_index, :], matplotlib=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 694
        },
        "id": "OXOdmIrudjEV",
        "outputId": "25816998-aeb6-4202-f0bc-d3c8abcb7d54"
      },
      "outputs": [],
      "source": [
        "shap.plots.waterfall(shap_values[sample_index], max_display=14)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPV8BuKp3XEE"
      },
      "source": [
        "#### Features interpretability: How to explain a single prediction ?\n",
        "\n",
        "**Tools**:\n",
        "- *Scatter plot*: on a scatter plot, we observe how, for one chosen features, its value impacts the Shapley values. The vertical dispersion in the plot above shows that the same value for the feature can have a different impact on the model’s output for different people.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "Ox9rNFrp3wye",
        "outputId": "44755414-e97c-4230-98d4-dc56782681fe"
      },
      "outputs": [],
      "source": [
        "shap.plots.scatter(shap_values[:, \"Age\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wuR3l0P3ypo"
      },
      "source": [
        "To understand, which other feature might explain the vertical dispersion, we can color the scatter plot with another feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "id": "h4Vvb1Xx3w4e",
        "outputId": "07cedfd0-2f4f-4f9a-cf90-8c6a51f67ddc"
      },
      "outputs": [],
      "source": [
        "shap_values.display_data = X_display.values\n",
        "shap.plots.scatter(shap_values[:, \"Age\"],\n",
        "                   color=shap_values[:, \"Education-Num\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ahFUtgk4NJ9"
      },
      "source": [
        "**QUESTION**: Can you comment on the effect of the interaction between Education-Num and Age ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 470
        },
        "id": "5-jZQRI85FRd",
        "outputId": "5456147a-4c52-460d-d261-b9b76ff17b3e"
      },
      "outputs": [],
      "source": [
        "shap.plots.scatter(shap_values[:, \"Capital Gain\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFuBIo235NAG"
      },
      "source": [
        "**QUESTION**: How can you interpret the impact of Capital Gain ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_TZg4uO4bIj"
      },
      "source": [
        "#### Global interpretibility\n",
        "\n",
        "**Tools**:\n",
        "- *Summary plot*: The SHAP summary plot allows us to understand the model by ranking the features from the most relevant to the least important ones. Each datapoint represents a different person."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "id": "t6eKIoM6fQ40",
        "outputId": "d1f17803-875d-40c4-9370-029029872514"
      },
      "outputs": [],
      "source": [
        "shap.summary_plot(shap_values, X)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
